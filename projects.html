<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Miruku Zhang</title>

    <!-- CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet" type="text/css">
    <link href="font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="css/nivo-lightbox.css" rel="stylesheet" />
    <link href="css/nivo-lightbox-theme/default/default.css" rel="stylesheet" type="text/css" />
    <link href="css/owl.carousel.css" rel="stylesheet" media="screen" />
    <link href="css/owl.theme.css" rel="stylesheet" media="screen" />
    <link href="css/animate.css" rel="stylesheet" />
    <link href="css/style.css" rel="stylesheet">
    <link href="color/default.css" rel="stylesheet">
    <link href="css/kmeans.css"  rel="stylesheet" >

    <script src="https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js" charset="utf-8"></script>


</head>

<body id="page-top" data-spy="scroll" data-target=".navbar-custom">
    <!-- Preloader -->
    <div id="preloader">
        <div id="load"></div>
    </div>

    <section id="intro" class="intro">
    
        <!-- <div class="slogan">
          <a href="index.html"><img src="img/logo.png" alt="" /></a>
        </div>
        <div class="page-scroll">
          <a href="#about">
    			<i class="fa fa-angle-down fa-5x animated"></i>
    	  </a>
        </div> -->
        <canvas width="1000" height="1000" style="position:absolute;left:0;top:0;overflow: hidden"></canvas>
        <div id="title_wrapper">
            <h1 id="site_title" data-0="opacity: 1; top:0px;" data-600="opacity: 0; top: 80px;" data-anchor-target="#site_title" class="skrollable skrollable-between"
                style="opacity: 1; top: 53.3333px;">
                <a style="color:rgb(172,31,45)">Miruku</a> H. Zhang
            </h1>
    
            <!-- Site Slogan -->
            <h2 id="site_slogan" data-0="opacity: 1; top:0px;" data-600="opacity: 0; top: 80px;" data-anchor-target="#site_slogan" class="skrollable skrollable-between"
                style="opacity: 1; top: 63.3333px;">
                Ph.D. Student of ECE at
                <a style="color:rgb(172,31,45)">Cornell</a>
            </h2>
            <!-- Scroll down button -->
            <!-- <div id="scroll_down_button" data-0="opacity: 1; top:0px;" data-400="opacity: 0; top: 100px;" data-anchor-target="#scroll_down_button" _vimium-has-onclick-listener="" class="skrollable skrollable-between" style="opacity: 0; top: 100px;">
                <i class="fa fa-angle-down"></i>
            </div> -->
        </div>
    </section>
    <!-- /Section: intro -->
    
    <!-- Navigation -->
    <div id="navigation">
        <nav class="navbar navbar-custom" role="navigation">
            <div class="container">
                <div class="row">
                    <div class="col-md-12">
    
                        <!-- Brand and toggle get grouped for better mobile display -->
                        <div class="navbar-header">
                            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#menu">
                                <i class="fa fa-bars"></i>
                            </button>
                        </div>
                        <!-- Collect the nav links, forms, and other content for toggling -->
                        <div class="collapse navbar-collapse" id="menu">
                            <ul class="nav navbar-nav">
                                <li class="active">
                                    <a href="./index.html">Home</a>
                                </li>
                                <li class="active">
                                    <a href="./gallery.html">Summer Projets</a>
                                </li>
                            </ul>
                        </div>
                        <!-- /.Navbar-collapse -->
    
                    </div>
                </div>
            </div>
            <!-- /.container -->
        </nav>
    </div>
    <!-- /Navigation -->

    <section id="amodal" class="home-section">
        <div class="container">
            <div class="row  text-center">
                <div class="col-lg-12">
                    <div class="section-heading">
                        <h3>Amodal Semantic Segmentation for Street Scene Understanding</h3>
                        <p style="text-align:justify;">In this project, we would like segment the street scene in a different way, i.e. amodal segmentation[1][2]. Road detection is essential for street scene understanding, however, roads are covered by vehicles and pedestrians all the time. So how to segment the road with its full contour remains a problem. Here we resort to amodal segmentation to resolve this issue, where we treat each pixel with more than one labels if needed. We also refere this multi-label segmentation as layered segmentation, where an image is decomposed into different layers, and each layer has its own properties. <br>
                        Down below is an example, pixels in the region that the car covers on the road could be labeled with both car and road. </p>
                    </div>
                </div>
            </div>
            <div class="row">
                <div class="col-lg-12">
                    <img src="img/amodal.png" class="img-responsive img-rounded" alt="" />
                </div>
            </div>
        </div>
    
    </section>

    <section id="amodal" class="home-section">
        <div class="container">
            <div class="row  text-center">
                <div class="col-lg-12">
                    <div class="section-heading">
                        <h3>Domain Adaptation for Street Scene Understanding Under Different Weather Conditions</h3>
                        <p style="text-align:justify;">In this project, we would like to segment street scenes under different conditions, such as snow rain etc. Currently, most street scene datasets [3][4] are annotated with roads in a normal conditions, however, it is commonly to see roads covered with snow or people drive our in a rainy day. These weather conditions throw a big threat to deep learning models trained on current datasets, and it is very unefficient and time-consuming to annotate another dataset based on just a new weather condition. Thus, we resot to using domain adaptation methods to take just a few shots of data in new conditions to train our model. <br>
                        Down below is an example we use the state-of-the-art methods to segment street scene in Ithaca, NY 14850. We can see from the figures when in snow, the segmentation performance degragdes sharply.
                        </p>
                    </div>
                </div>
            </div>
            <div class="row">
                <div class="col-lg-12">
                    <img src="img/nosnow.png" class="img-responsive img-rounded" alt="" />
                </div>
            </div>
            <div class="row">
                <div class="col-lg-12">
                    <img src="img/withsnow.png" class="img-responsive img-rounded" alt="" />
                </div>
            </div>
        </div>
    
    </section>

    <section id="amodal" class="home-section">
        <div class="container">
            <div class="row  text-center">
                <div class="col-lg-12">
                    <div class="section-heading">
                        <h3>Self-taught Learning for Automatic Lidar Data Annotation </h3>
                        <p style="text-align:justify;">In this project, we would like to anotate our lidar data automaticly and further use this data to perform lidar segmentation. The sparse properties of lidar data makes it hard to anotate, though some researchers have tried to annotate the lidar data, there are only a limited number data samples available [5]. Here we resort to self-taught learning, where we can learn from video reply [6]. We plan to use camera and current street scene segmentation method to help annotate lidar data. <br> 
                        Down below is an example of lidar information received.
                        </p>

                    </div>
                </div>
            </div>
            <div class="row">
                <div class="col-lg-12">
                    <img src="img/lidar.png" class="img-responsive img-rounded" alt="" />
                </div>
            </div>
        </div>
    
    </section>
    
    <section id="amodal" class="home-section">
        <div class="container">
            <div class="row  text-center">
                <div class="col-lg-12">
                    <div class="section-heading">
                        <h3>Simultaneously Sparse and Low-rank Weights Training for Convolutional Neural Networks</h3>
                        <p style="text-align:justify;">In this project, we would like to investigate how to train Convolutional Neural Networks while imposing simultaneously sparse and low-rank constraints on weight matrices. Weights with such constraints are more likely to avoid overfitting and potentially reduce parameters, which can help running CNN on resource-limited devices such as self-driving cars. <br>
                        There exists research [7] investigating how to decompose the weight matrix into sparse and low-rank components and train the weights in a differfent framework. However, it is imperative to develop a unified frame work to train CNN and directly imposing sparse and low-rank constraints on weight matrices instead of decomposition.
                        <br>
                        Down below is an example from [7], which decompose the weight matrix into sparse and low-rank components. 
                        </p>
                    </div>
                </div>
            </div>
            <div class="row">
                <div class="col-lg-12">
                    <img src="img/sparse.png" class="img-responsive img-rounded" alt="" />    
                </div>
            </div>
        </div>
    
    </section>

    <section id="amodal" class="home-section">
        <div class="container">
            <div class="row  text-center">
                <div class="col-lg-12">
                    <div class="section-heading">
                        <h3>Web Tools for Interactive Machine Learning Education and Data Mining with Data Collected from Users</h3>
                        <p style="text-align:justify;">With the advancements of computational resources and volume collections of data, deep learning has been widely used in many fields and becomes one of the hottest topics in the world, which will lead to a huge revolution in human’s daily life. <br>
                        With such unstoppable trend, people from different backgrounds are intrigued by this fascinating new technology and trying to explore it. With the benefit of internet, people can find lots of sources, like Coursera and Udacity, to learn deep learning. However, for most people, who have little math/statistics/programming background but interested in deep learning, these sources are not that intuitive and lack of hands-on instructions. Thus, we are aiming to build up an Interactive online educational platform to provide services for the people with little math/statistics/programming background but would like to learn or directly use deep learning. <br>
                        In the meanwhile, we will collect data and statistics from users when using our platform. These data will be exmained by researchers to discover useful information to analyze the user behavior, which will further help us build the platform and improve user experience.  <br>
                        Down below is an example that we use <a style="color:rgb(172,31,45)">deep reinforcement learning</a> to train a flappy bird game. (More efforts need to be done to make this educational applicable) <br>
                        Press <a style="color:rgb(172,31,45)">space to start training</a>, press <a style="color:rgb(172,31,45)">space</a> again to stop training and enter the human-control mode to give some positive feedback to our learner. Press <a style="color:rgb(172,31,45)">left arrow to jump<a/> and <a style="color:rgb(172,31,45)">right arrow to stay</a>.
                    </p>


                    </div>
                </div>
            </div>
            <div class="row text-center">
                <div class="col-lg-12">
                    <iframe src="./floppybird/index.html" style="height:650px;width:400px;"></iframe>
                </div>

            </div>
        </div>
    
    </section>

    <section id="publications" class="home-section">
        <div class="container">
            <div class="row">
                <div class="col-lg-8">
                    <div class="section-heading">
                        <h3>References</h3>
                    </div>
                </div>
            </div>
        </div>
        <div class="container">
            <div style="text-align: left; margin-top:10px" class="col-md-12">
                <ul>
                    <li>
                        [1] Semantic Amodal Segmentation,
                        <br /> Yan Zhu, Yuandong Tian, Dimitris Mexatas, Piotr Dollár,
                        <br />
                        <i>CVPR 2017</i>.
                        <br />
                        <p></p>
                    </li>
                    <li>
                        [2] Amodal Instance Segmentation,
                        <br /> Ke Li, Jitendra Malik,
                        <br />
                        <i>ECCV 2016</i>.
                        <br />
                        <p></p>
                    </li>
                    <li>
                        [3] The Cityscapes Dataset for Semantic Urban Scene Understanding,
                        <br /> M. Cordts, M. Omran, S. Ramos, T. Rehfeld, M. Enzweiler, R. Benenson, U. Franke, S. Roth, and B. Schiele,
                        <br />
                        <i>CVPR 2016</i>.
                        <br />
                        <p></p>
                    </li>
                    <li>
                        [4] The Cityscapes Dataset,
                        <br /> M. Cordts, M. Omran, S. Ramos, T. Scharwächter, M. Enzweiler, R. Benenson, U. Franke, S. Roth, and B. Schiele,
                        <br />
                        <i>CVPRW 2015</i>.
                        <br />
                        <p></p>
                    </li>
                    <li>
                        [5] Object Scene Flow for Autonomous Vehicles,
                        <br /> Moritz Menze and Andreas Geiger,
                        <br />
                        <i>CVPR 2015</i>.
                        <br />
                        <p></p>
                    </li>
                    <li>
                        [6] Learning Where to Drive by Watching Others,
                        <br /> Miguel A. Bautista, Patrick Fuchs, Björn Ommer,
                        <br />
                        <i>GCPR 2017</i>.
                        <br />
                        <p></p>
                    </li>
                    <li>
                        [7] On Compressing Deep Models by Low Rank and Sparse Decomposition,
                        <br /> Xiyu Yu, Tongliang Liu, Xinchao Wang, Dacheng Tao,
                        <br />
                        <i>CVPR 2017</i>.
                        <br />
                        <p></p>
                    </li>
                </ul>
            </div>
        </div>
                
    </section>

    <footer>
        <div class="container">
            <div class="row">
                <div class="col-md-12 col-lg-12">
                    <a href="http://www.ece.cornell.edu/">
                        <img src="img/ece.png" class="img-responsive img-rounded" alt="" />
                    </a>
                </div>
                <div class="col-md-12 col-lg-12">
                    <p>&copy;
                        <a style="color:red">Miruku</a> H. Zhang</p>
                    <div class="credits">
                        All rights reserved.
                    </div>
                </div>
            </div>
        </div>
    </footer>


    <!-- Core JavaScript Files -->
    <script src="js/jquery.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <script src="js/jquery.easing.min.js"></script>
    <script src="js/jquery.transit.min.js"></script>    
    <script src="js/jquery.sticky.js"></script>
    <script src="js/jquery.scrollTo.js"></script>
    <script src="js/stellar.js"></script>
    <script src="js/wow.min.js"></script>
    <script src="js/owl.carousel.min.js"></script>
    <script src="js/nivo-lightbox.min.js"></script>
    <!-- Custom Theme JavaScript -->
    <script src="js/custom.js"></script>
    <script src="contactform/contactform.js"></script>
    <!-- <script src="https://d3js.org/d3-timer.v1.min.js"></script> -->
    <script src="js/particles.js"></script>
    <script src="js/easymljs.js"></script>
    <script src="js/kmeansd3.js"></script>
    <script src="js/jquery-1.8.3.min.js"></script>


</body>

</html>
